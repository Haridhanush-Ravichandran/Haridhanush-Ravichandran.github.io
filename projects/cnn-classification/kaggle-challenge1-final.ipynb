{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":96834,"databundleVersionId":11751646,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision import transforms\nimport torch.nn as nn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau,CosineAnnealingLR\n\nclass EarlyStopping:\n    def __init__(self, patience=5):\n        self.patience = patience\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        return self.early_stop","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UNIPD - Deep Learning 2025 - Challenge 1 Template\n\nThis is a simple template for the challenge. Feel free to adapt it to your needs.","metadata":{}},{"cell_type":"markdown","source":"The following cell contains Kaggle default instruction:","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os.path as osp\nimport os\nimport csv\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"\n\nclass ImageDataset(Dataset):\n    def __init__(self, root: str, test: bool = False, transform=None):\n        super().__init__()\n        self.root = root\n        self.transform = transform or transforms.Compose([    \n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomRotation(degrees=10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),  # slight translation\n            transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # mimic viewpoint shift\n            transforms.ToTensor(),\n            transforms.RandomErasing(p=0.3, scale=(0.02, 0.15), ratio=(0.3, 3.3)),  # occlusion regularization\n            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        ])\n        self.test = test\n\n        self.img_path = osp.join(root, 'images')\n        self.targets = []\n        self.ids = []\n\n        if not test:\n            # Load images and labels\n            labels_path = osp.join(root, 'labels.csv')\n            with open(labels_path, 'r') as csvfile:\n                reader = csv.DictReader(csvfile)\n                for row in reader:\n                    image_id = row['id'].zfill(5)\n                    label = int(row['label'])\n                    self.targets.append(label)\n                    self.ids.append(image_id)\n        else:\n            # Test mode: no labels.csv\n            for fname in sorted(os.listdir(self.img_path)):\n                if fname.endswith('.jpeg'):\n                    image_id = fname[:-5].zfill(5)\n                    self.ids.append(image_id)\n\n    def __getitem__(self, index: int):\n        img_id = self.ids[index]\n        img_file = osp.join(self.img_path, f'{img_id}.jpeg')\n        img = Image.open(img_file).convert('RGB')\n        \n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.test:\n            return img, img_id\n        else:\n            target = self.targets[index]\n            return img, target\n\n    def __len__(self) -> int:\n        return len(self.ids)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datasets_dir = '/kaggle/input/unipd-deep-learning-2025-challenge-1'\n\n# create datasets\ntrain_dataset = ImageDataset(osp.join(datasets_dir, 'train_dataset'), test=False)\ntest_dataset = ImageDataset(osp.join(datasets_dir, 'test_dataset'), test=True)\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Test dataset size: {len(test_dataset)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# Check the shape of a sample\nsample_image, sample_label = next(iter(train_loader))\nprint(f\"Batch image shape: {sample_image.shape}\")\nprint(f\"Batch label shape: {sample_label.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torchvision\n\n# Get one batch\nimages, labels = next(iter(train_loader))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Definition","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass ImageClassifier(nn.Module):\n    def __init__(self, num_classes=20):\n        super(ImageClassifier, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),  # 64x64\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),  # 32x32\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),  # 16x16\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2), # down to 8x8\n            \n            nn.AdaptiveAvgPool2d((2,2))  # ensures consistent output size\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.4),\n            nn.Linear(256 * 2 * 2, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        return self.classifier(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = ImageClassifier().to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.utils.data import DataLoader,Subset\nfrom sklearn.model_selection import train_test_split\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#model = ImageClassifier(num_classes=20).to(device)\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\nearly_stopper = EarlyStopping(patience=15)\nEPOCHS = 100\n\nindices = list(range(len(train_dataset)))\nlabels = [train_dataset[i][1] for i in indices] \ntrain_indices, val_indices = train_test_split(\n    indices,\n    test_size=0.1,\n    stratify=labels,\n    random_state=42\n)\n\n# 3. Create Subsets\ntrain_subset = Subset(train_dataset, train_indices)\nval_subset = Subset(train_dataset, val_indices)\ntrain_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n\nbest_val_acc=0.0\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    # Evaluation on validation set\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_loss /= total\n    val_accuracy = 100 * correct / total\n\n    print(f\"Epoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n\n# Scheduler step\n    scheduler.step(val_loss)\n    if val_accuracy > best_val_acc:\n        best_val_acc = val_accuracy\n        torch.save(model.state_dict(), 'best_model.pt')\n    if early_stopper(val_loss):\n        print(\"Early stopping triggered.\")\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test Predictions","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor images, img_ids in test_loader:\n    preds = model(images.to(device))\n    predicted_labels = preds.argmax(dim=1)  # Get the indices of the maximum value along dim=1\n    results.extend(zip(img_ids, predicted_labels.cpu().numpy()))  # Make sure to move the labels back to CPU if needed and convert to numpy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\nsubmission_df = pd.DataFrame(results, columns=['id', 'label'])\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.to_csv('Submission_.csv',index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}